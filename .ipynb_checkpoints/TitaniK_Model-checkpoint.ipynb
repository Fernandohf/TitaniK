{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be downloaded using [Kaggle's API](https://github.com/Kaggle/kaggle-api#api-credentials). For your own use, you will need to create a API key in **Account Settings**. On windows, you shoudl create the folder `.kaggle` inside your user and add the file `kaggle.json` donwloaded from the API.\n",
    "\n",
    "After this, you can install and use the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\program files\\python36\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: python-slugify in c:\\program files\\python36\\lib\\site-packages (from kaggle) (1.2.6)\n",
      "Requirement already satisfied: urllib3<1.23.0,>=1.15 in c:\\program files\\python36\\lib\\site-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: certifi in c:\\program files\\python36\\lib\\site-packages (from kaggle) (2017.7.27.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\program files\\python36\\lib\\site-packages (from kaggle) (2.6.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\program files\\python36\\lib\\site-packages (from kaggle) (1.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python36\\lib\\site-packages (from kaggle) (4.28.1)\n",
      "Requirement already satisfied: requests in c:\\program files\\python36\\lib\\site-packages (from kaggle) (2.18.4)\n",
      "Requirement already satisfied: Unidecode>=0.04.16 in c:\\program files\\python36\\lib\\site-packages (from python-slugify->kaggle) (1.0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\program files\\python36\\lib\\site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\program files\\python36\\lib\\site-packages (from requests->kaggle) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list all competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502 - Bad Gateway\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our especific competition data, in this case: **titanic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                   size  creationDate         \n",
      "---------------------  ----  -------------------  \n",
      "train.csv              60KB  2013-06-28 13:40:25  \n",
      "test.csv               28KB  2013-06-28 13:40:24  \n",
      "gender_submission.csv   3KB  2017-02-01 01:49:18  \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions files -c titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, download the files to `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.csv to D:\\ARQUIVOS PESSOAIS\\GitHub\\TitaniK\\.ipynb_checkpoints\n",
      "\n",
      "Downloading test.csv to D:\\ARQUIVOS PESSOAIS\\GitHub\\TitaniK\\.ipynb_checkpoints\n",
      "\n",
      "Downloading gender_submission.csv to D:\\ARQUIVOS PESSOAIS\\GitHub\\TitaniK\\.ipynb_checkpoints\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/59.8k [00:00<?, ?B/s]\n",
      "100%|##########| 59.8k/59.8k [00:00<00:00, 426kB/s]\n",
      "\n",
      "  0%|          | 0.00/28.0k [00:00<?, ?B/s]\n",
      "100%|##########| 28.0k/28.0k [00:00<00:00, 1.02MB/s]\n",
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 136kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iapz_gk4bL4Q"
   },
   "source": [
    "# 1 - Introducing data science workflows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MG9jSDw-wVhY"
   },
   "source": [
    "\n",
    "\n",
    "In this guided project, we're going to put together all that we've learned in this course and create a data science workflow.\n",
    "\n",
    "By defining a workflow for yourself, you can give yourself a framework with which to make iterating on ideas quicker and easier, allowing yourself to work more efficiently.\n",
    "\n",
    "In this mission, we're going to explore a workflow to make competing in the Kaggle Titanic competition easier, using a pipeline of functions to reduce the number of dimensions you need to focus on.\n",
    "\n",
    "To get started, we'll read in the original **train.csv** and **test.csv** files from Kaggle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWquy7FRbL4R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "holdout = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPE04u4RbL4V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P92sW6bzbL4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpDHDy1PbL4e"
   },
   "outputs": [],
   "source": [
    "survived = train[\"Survived\"]\n",
    "train = train.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXGN8riJbL4h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBcr5bYhbL4j",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKIcnJyhbL4n"
   },
   "outputs": [],
   "source": [
    "## concatenate all data to guarantee that dataset have the same columns\n",
    "all_data = pd.concat([train, holdout], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGbcWYNjbL4p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 11)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPZr6A-JbL4s"
   },
   "source": [
    "# 2 - Exploring the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TwwXZJhMwsER"
   },
   "source": [
    "\n",
    "\n",
    "In the first three missions of this course, we have done a variety of activities, mostly in isolation: **Exploring the data**, **creating features**, **selecting features**, **selecting and tuning different models**.\n",
    "\n",
    "The Kaggle workflow we are going to build will combine all of these into a process.\n",
    "\n",
    "<img width=\"400\" alt=\"creating a repo\" src=\"https://drive.google.com/uc?export=view&id=1swb6PxXUJuDvv83ylqh9eUh992lXTu47\">\n",
    "\n",
    "- **Data exploration**, to find patterns in the data\n",
    "- **Feature engineering**, to create new features from those patterns or through pure experimentation\n",
    "- **Feature selection**, to select the best subset of our current set of features\n",
    "- **Model selection/tuning**, training a number of models with different hyperparameters to find the best performer.\n",
    "\n",
    "We can continue to repeat this cycle as we work to optimize our predictions. At the end of any cycle we wish, we can also use our model to make predictions on the holdout set and then **Submit to Kaggle** to get a leaderboard score.\n",
    "\n",
    "While the first two steps of our workflow are relatively freeform, later in this project we'll create some functions that will help automate the complexity of the latter two steps so we can move faster.\n",
    "\n",
    "For now, let's practice the first stage, exploring the data. We're going to examine the two columns that contain information about the family members each passenger had onboard: **SibSp** and **Parch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqMGzwrQbL4t"
   },
   "source": [
    "# 3 - Preprocesing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFiller(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Applies data filling to NaN values in selected features.\n",
    "    \n",
    "    > cols_filler: dictionary with columns and filling values / strategy\n",
    "    e.g. {\"A\": 0.5, \"B\": -2, \"C\": 'a', \"D\": 'mean'}\n",
    "    \"\"\"\n",
    "    def __init__(self, cols_filler):\n",
    "        \"\"\"\n",
    "        Inital input for the transformer.\n",
    "        \"\"\"\n",
    "        self.cols_filler = cols_filler\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Where the filling occurs.\n",
    "        \"\"\"\n",
    "        for k, v in self.cols_filler.items():\n",
    "            # Filling strategy\n",
    "            if v == 'mean':\n",
    "                filler = X[k].mean()\n",
    "            elif v == 'median':\n",
    "                filler = X[k].median()\n",
    "            else:\n",
    "                filler = v\n",
    "            \n",
    "            X[k] = X[k].fillna(filler)\n",
    "            \n",
    "        return X\n",
    "\n",
    "class DataOneHotEncoding(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Applies One Hot Encoding to selected features.\n",
    "    \n",
    "    > cols: list of columns to perform one hot encoding.\n",
    "    e.g. [\"A\", \"B\", \"C\"]\n",
    "    \"\"\"\n",
    "    def __init__(self, cols, inplace=True):\n",
    "        \"\"\"\n",
    "        Inital input for the transformer.\n",
    "        \"\"\"\n",
    "        self.cols = cols\n",
    "        self.inplace = inplace\n",
    "    \n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Where the encoding occurs.\n",
    "        \"\"\"\n",
    "        for col in self.cols:\n",
    "            # Get dummies columns\n",
    "            dummies = pd.get_dummies(X[col], prefix=col)\n",
    "            # Join with data X\n",
    "            X = pd.concat([X, dummies], axis=1)\n",
    "        # Remove old columns\n",
    "        if self.inplace:\n",
    "            print(X.shape)\n",
    "            X = X.drop(self.cols, axis=1)\n",
    "            print(X.shape)\n",
    "            \n",
    "        return X\n",
    "\n",
    "class DataBinning(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Applies binnig to selected features.\n",
    "    \n",
    "    > dict_of_cols: dictionary of dictionaries with cut_points and labels for each column.\n",
    "    e.g. {\"A\":{'cut_points':[1,2,3], 'labels':['a', 'b']}, \"B\": {...}, ...}\n",
    "    \"\"\"\n",
    "    def __init__(self, dict_of_cols, inplace=True):\n",
    "        \"\"\"\n",
    "        Inital input for the transformer.\n",
    "        \"\"\"\n",
    "        self.dict_cols = dict_of_cols\n",
    "        self.inplace = inplace\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Where the binning occurs.\n",
    "        \"\"\"\n",
    "        for k, v in self.dict_cols.items():\n",
    "            # Cut points data\n",
    "            cut_points = v['cut_points']\n",
    "            \n",
    "            # Labels data\n",
    "            label_names = v['labels']\n",
    "            \n",
    "            # Creates new columns inplace\n",
    "            if self.inplace:\n",
    "                X[k] = pd.cut(X[k], cut_points, labels=label_names)\n",
    "            else:\n",
    "                k = k + '_binned'\n",
    "                X[k] = pd.cut(X[k], cut_points, labels=label_names)\n",
    "            \n",
    "            # Set dtype to categorical\n",
    "            X[k] = X[k].astype('category')\n",
    "            \n",
    "        return X\n",
    "    \n",
    "class DataProcess(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Applies application-specific process to selected features.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Where the processing occurs.\n",
    "        \"\"\"\n",
    "        # Process Tickets column\n",
    "        ticket_cod = []\n",
    "        ticket_number = []\n",
    "        for index, ticket in X.Ticket.iteritems():\n",
    "            if not ticket.isdigit():\n",
    "                # Take prefix\n",
    "                split = ticket.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')\n",
    "                ticket_cod.append(split[0])\n",
    "                # Take ticket number\n",
    "                try:\n",
    "                    ticket_number.append(int(split[1]))\n",
    "                except:\n",
    "                    ticket_number.append(-1)\n",
    "            else:\n",
    "                ticket_cod.append(\"X\")\n",
    "                try:\n",
    "                    ticket_number.append(int(ticket))\n",
    "                except:\n",
    "                    ticket_number.append(-1)\n",
    "        X[\"Ticket_cod\"] = ticket_cod\n",
    "        X[\"Ticket_number\"] = ticket_number\n",
    "        X = X.drop('Ticket',axis=1)\n",
    "        \n",
    "        # Process titles\n",
    "        titles = {\"Mr\" :         \"Mr\",\n",
    "                  \"Mme\":         \"Mrs\",\n",
    "                  \"Ms\":          \"Mrs\",\n",
    "                  \"Mrs\" :        \"Mrs\",\n",
    "                  \"Master\" :     \"Master\",\n",
    "                  \"Mlle\":        \"Miss\",\n",
    "                  \"Miss\" :       \"Miss\",\n",
    "                  \"Capt\":        \"Officer\",\n",
    "                  \"Col\":         \"Officer\",\n",
    "                  \"Major\":       \"Officer\",\n",
    "                  \"Dr\":          \"Officer\",\n",
    "                  \"Rev\":         \"Officer\",\n",
    "                  \"Jonkheer\":    \"Royalty\",\n",
    "                  \"Don\":         \"Royalty\",\n",
    "                  \"Sir\" :        \"Royalty\",\n",
    "                  \"Countess\":    \"Royalty\",\n",
    "                  \"Dona\":        \"Royalty\",\n",
    "                  \"Lady\" :       \"Royalty\"}\n",
    "        extracted_titles = X[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        X[\"Title\"] = extracted_titles.map(titles)\n",
    "        X = X.drop('Name',axis=1)\n",
    "        \n",
    "        # Process Cabin\n",
    "        cabin_cod = []\n",
    "        cabin_number = []\n",
    "        for index, cabin in X.Cabin.iteritems():\n",
    "            if isinstance(cabin, str):\n",
    "                # Take prefix\n",
    "                split = cabin.strip().split(' ')[-1]\n",
    "                cabin_cod.append(split[0])\n",
    "                # Cabin number\n",
    "                try:\n",
    "                    cabin_number.append(int(split[1:]))\n",
    "                except:\n",
    "                    cabin_number.append(-1)\n",
    "            else:\n",
    "                cabin_cod.append('Unknown') \n",
    "                cabin_number.append(-1)\n",
    "        X[\"Cabin_type\"] = cabin_cod\n",
    "        X[\"Cabin_number\"] = cabin_number\n",
    "        X = X.drop('Cabin',axis=1)\n",
    "        \n",
    "        # Is alone\n",
    "        X[\"Family_size\"] = X[[\"SibSp\",\"Parch\"]].sum(axis=1)\n",
    "        X[\"Alone\"] = (X[\"Family_size\"] == 0)\n",
    "        \n",
    "        # Is male\n",
    "        X[\"Male\"] = X[\"Sex\"] == 'male'\n",
    "        X = X.drop(\"Sex\", axis=1)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 99)\n",
      "(1309, 90)\n"
     ]
    }
   ],
   "source": [
    "# input dictionaries\n",
    "dict_fill = { \"Fare\": \"median\",\n",
    "              \"Embarked\": \"S\",\n",
    "              \"Age\": -0.5\n",
    "            }\n",
    "dict_binning = {\"Age\": {\"cut_points\": [-5, 0, 5, 12, 18, 35, 60, 100],\n",
    "                         \"labels\": [\"Missing\", \"Infant\", \"Child\", \"Teenager\",\n",
    "                                    \"Young Adult\", \"Adult\", \"Senior\"]},\n",
    "                \"Fare\": {\"cut_points\": [-5, 12, 50, 100, 1000],\n",
    "                         \"labels\": [\"0-12\",\"12-50\",\"50-100\",\"100+\"]},\n",
    "                \"Cabin_number\": {\"cut_points\": [-5, 0, 50, 100, 150, 200, 250, 300, 1000],\n",
    "                                 \"labels\": [\"Unknown\", \"0-50\", \"50-100\",\n",
    "                                            \"100-150\", \"150-200\", \"200-250\", \"250-300\", \"300+\"]},\n",
    "                \"Ticket_number\": {\"cut_points\": [-5, 0, 2000, 10000, 50000,\n",
    "                                                 250000, 500000, 10000000],\n",
    "                                  \"labels\": [\"Unknown\", \"0-2k\", \"2k-10k\", \"10k-50k\",\n",
    "                                             \"50k-250k\", \"250k-500k\", \"500k+\"]}\n",
    "               }\n",
    "one_hot_cols = [\"Age\", \"Fare\", \"Embarked\", \n",
    "                \"Ticket_cod\", \"Ticket_number\", \"Title\",\n",
    "                \"Cabin_type\", \"Cabin_number\", \"Pclass\"\n",
    "]   \n",
    "\n",
    "# Pipeline definition\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('filling', DataFiller(dict_fill)),\n",
    "                     ('processing', DataProcess()),\n",
    "                     ('binnig', DataBinning(dict_binning)),\n",
    "                     ('one_hot_encoding', DataOneHotEncoding(one_hot_cols))\n",
    "])\n",
    "\n",
    "transformed_data = pipeline.transform(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'SibSp', 'Parch', 'Family_size', 'Alone', 'Male',\n",
      "       'Age_Missing', 'Age_Infant', 'Age_Child', 'Age_Teenager',\n",
      "       'Age_Young Adult', 'Age_Adult', 'Age_Senior', 'Fare_0-12', 'Fare_12-50',\n",
      "       'Fare_50-100', 'Fare_100+', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
      "       'Ticket_cod_A', 'Ticket_cod_A4', 'Ticket_cod_A5', 'Ticket_cod_AQ3',\n",
      "       'Ticket_cod_AQ4', 'Ticket_cod_AS', 'Ticket_cod_C', 'Ticket_cod_CA',\n",
      "       'Ticket_cod_CASOTON', 'Ticket_cod_FC', 'Ticket_cod_FCC',\n",
      "       'Ticket_cod_Fa', 'Ticket_cod_LINE', 'Ticket_cod_LP', 'Ticket_cod_PC',\n",
      "       'Ticket_cod_PP', 'Ticket_cod_PPP', 'Ticket_cod_SC', 'Ticket_cod_SCA3',\n",
      "       'Ticket_cod_SCA4', 'Ticket_cod_SCAH', 'Ticket_cod_SCOW',\n",
      "       'Ticket_cod_SCPARIS', 'Ticket_cod_SCParis', 'Ticket_cod_SOC',\n",
      "       'Ticket_cod_SOP', 'Ticket_cod_SOPP', 'Ticket_cod_SOTONO2',\n",
      "       'Ticket_cod_SOTONOQ', 'Ticket_cod_SP', 'Ticket_cod_STONO',\n",
      "       'Ticket_cod_STONO2', 'Ticket_cod_STONOQ', 'Ticket_cod_SWPP',\n",
      "       'Ticket_cod_WC', 'Ticket_cod_WEP', 'Ticket_cod_X',\n",
      "       'Ticket_number_Unknown', 'Ticket_number_0-2k', 'Ticket_number_2k-10k',\n",
      "       'Ticket_number_10k-50k', 'Ticket_number_50k-250k',\n",
      "       'Ticket_number_250k-500k', 'Ticket_number_500k+', 'Title_Master',\n",
      "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Title_Royalty',\n",
      "       'Cabin_type_A', 'Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D',\n",
      "       'Cabin_type_E', 'Cabin_type_F', 'Cabin_type_G', 'Cabin_type_T',\n",
      "       'Cabin_type_Unknown', 'Cabin_number_Unknown', 'Cabin_number_0-50',\n",
      "       'Cabin_number_50-100', 'Cabin_number_100-150', 'Cabin_number_150-200',\n",
      "       'Cabin_number_200-250', 'Cabin_number_250-300', 'Cabin_number_300+',\n",
      "       'Pclass_1', 'Pclass_2', 'Pclass_3'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Male</th>\n",
       "      <th>Age_Missing</th>\n",
       "      <th>Age_Infant</th>\n",
       "      <th>Age_Child</th>\n",
       "      <th>Age_Teenager</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_number_0-50</th>\n",
       "      <th>Cabin_number_50-100</th>\n",
       "      <th>Cabin_number_100-150</th>\n",
       "      <th>Cabin_number_150-200</th>\n",
       "      <th>Cabin_number_200-250</th>\n",
       "      <th>Cabin_number_250-300</th>\n",
       "      <th>Cabin_number_300+</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  SibSp  Parch  Family_size  Alone   Male  Age_Missing  \\\n",
       "0              1      1      0            1  False   True            0   \n",
       "1              2      1      0            1  False  False            0   \n",
       "2              3      0      0            0   True  False            0   \n",
       "3              4      1      0            1  False  False            0   \n",
       "4              5      0      0            0   True   True            0   \n",
       "5              6      0      0            0   True   True            1   \n",
       "6              7      0      0            0   True   True            0   \n",
       "7              8      3      1            4  False   True            0   \n",
       "8              9      0      2            2  False  False            0   \n",
       "9             10      1      0            1  False  False            0   \n",
       "10            11      1      1            2  False  False            0   \n",
       "11            12      0      0            0   True  False            0   \n",
       "12            13      0      0            0   True   True            0   \n",
       "13            14      1      5            6  False   True            0   \n",
       "14            15      0      0            0   True  False            0   \n",
       "15            16      0      0            0   True  False            0   \n",
       "16            17      4      1            5  False   True            0   \n",
       "17            18      0      0            0   True   True            1   \n",
       "18            19      1      0            1  False  False            0   \n",
       "19            20      0      0            0   True  False            1   \n",
       "20            21      0      0            0   True   True            0   \n",
       "21            22      0      0            0   True   True            0   \n",
       "22            23      0      0            0   True  False            0   \n",
       "23            24      0      0            0   True   True            0   \n",
       "24            25      3      1            4  False  False            0   \n",
       "25            26      1      5            6  False  False            0   \n",
       "26            27      0      0            0   True   True            1   \n",
       "27            28      3      2            5  False   True            0   \n",
       "28            29      0      0            0   True  False            1   \n",
       "29            30      0      0            0   True   True            1   \n",
       "..           ...    ...    ...          ...    ...    ...          ...   \n",
       "388         1280      0      0            0   True   True            0   \n",
       "389         1281      3      1            4  False   True            0   \n",
       "390         1282      0      0            0   True   True            0   \n",
       "391         1283      0      1            1  False  False            0   \n",
       "392         1284      0      2            2  False   True            0   \n",
       "393         1285      0      0            0   True   True            0   \n",
       "394         1286      3      1            4  False   True            0   \n",
       "395         1287      1      0            1  False  False            0   \n",
       "396         1288      0      0            0   True   True            0   \n",
       "397         1289      1      1            2  False  False            0   \n",
       "398         1290      0      0            0   True   True            0   \n",
       "399         1291      0      0            0   True   True            0   \n",
       "400         1292      0      0            0   True  False            0   \n",
       "401         1293      1      0            1  False   True            0   \n",
       "402         1294      0      1            1  False  False            0   \n",
       "403         1295      0      0            0   True   True            0   \n",
       "404         1296      1      0            1  False   True            0   \n",
       "405         1297      0      0            0   True   True            0   \n",
       "406         1298      1      0            1  False   True            0   \n",
       "407         1299      1      1            2  False   True            0   \n",
       "408         1300      0      0            0   True  False            1   \n",
       "409         1301      1      1            2  False  False            0   \n",
       "410         1302      0      0            0   True  False            1   \n",
       "411         1303      1      0            1  False  False            0   \n",
       "412         1304      0      0            0   True  False            0   \n",
       "413         1305      0      0            0   True   True            1   \n",
       "414         1306      0      0            0   True  False            0   \n",
       "415         1307      0      0            0   True   True            0   \n",
       "416         1308      0      0            0   True   True            1   \n",
       "417         1309      1      1            2  False   True            1   \n",
       "\n",
       "     Age_Infant  Age_Child  Age_Teenager    ...     Cabin_number_0-50  \\\n",
       "0             0          0             0    ...                     0   \n",
       "1             0          0             0    ...                     0   \n",
       "2             0          0             0    ...                     0   \n",
       "3             0          0             0    ...                     0   \n",
       "4             0          0             0    ...                     0   \n",
       "5             0          0             0    ...                     0   \n",
       "6             0          0             0    ...                     1   \n",
       "7             1          0             0    ...                     0   \n",
       "8             0          0             0    ...                     0   \n",
       "9             0          0             1    ...                     0   \n",
       "10            1          0             0    ...                     1   \n",
       "11            0          0             0    ...                     0   \n",
       "12            0          0             0    ...                     0   \n",
       "13            0          0             0    ...                     0   \n",
       "14            0          0             1    ...                     0   \n",
       "15            0          0             0    ...                     0   \n",
       "16            1          0             0    ...                     0   \n",
       "17            0          0             0    ...                     0   \n",
       "18            0          0             0    ...                     0   \n",
       "19            0          0             0    ...                     0   \n",
       "20            0          0             0    ...                     0   \n",
       "21            0          0             0    ...                     0   \n",
       "22            0          0             1    ...                     0   \n",
       "23            0          0             0    ...                     1   \n",
       "24            0          1             0    ...                     0   \n",
       "25            0          0             0    ...                     0   \n",
       "26            0          0             0    ...                     0   \n",
       "27            0          0             0    ...                     1   \n",
       "28            0          0             0    ...                     0   \n",
       "29            0          0             0    ...                     0   \n",
       "..          ...        ...           ...    ...                   ...   \n",
       "388           0          0             0    ...                     0   \n",
       "389           0          1             0    ...                     0   \n",
       "390           0          0             0    ...                     1   \n",
       "391           0          0             0    ...                     1   \n",
       "392           0          0             1    ...                     0   \n",
       "393           0          0             0    ...                     0   \n",
       "394           0          0             0    ...                     0   \n",
       "395           0          0             1    ...                     1   \n",
       "396           0          0             0    ...                     0   \n",
       "397           0          0             0    ...                     1   \n",
       "398           0          0             0    ...                     0   \n",
       "399           0          0             0    ...                     0   \n",
       "400           0          0             0    ...                     1   \n",
       "401           0          0             0    ...                     0   \n",
       "402           0          0             0    ...                     0   \n",
       "403           0          0             1    ...                     0   \n",
       "404           0          0             0    ...                     1   \n",
       "405           0          0             0    ...                     1   \n",
       "406           0          0             0    ...                     0   \n",
       "407           0          0             0    ...                     0   \n",
       "408           0          0             0    ...                     0   \n",
       "409           1          0             0    ...                     0   \n",
       "410           0          0             0    ...                     0   \n",
       "411           0          0             0    ...                     0   \n",
       "412           0          0             0    ...                     0   \n",
       "413           0          0             0    ...                     0   \n",
       "414           0          0             0    ...                     0   \n",
       "415           0          0             0    ...                     0   \n",
       "416           0          0             0    ...                     0   \n",
       "417           0          0             0    ...                     0   \n",
       "\n",
       "     Cabin_number_50-100  Cabin_number_100-150  Cabin_number_150-200  \\\n",
       "0                      0                     0                     0   \n",
       "1                      1                     0                     0   \n",
       "2                      0                     0                     0   \n",
       "3                      0                     1                     0   \n",
       "4                      0                     0                     0   \n",
       "5                      0                     0                     0   \n",
       "6                      0                     0                     0   \n",
       "7                      0                     0                     0   \n",
       "8                      0                     0                     0   \n",
       "9                      0                     0                     0   \n",
       "10                     0                     0                     0   \n",
       "11                     0                     1                     0   \n",
       "12                     0                     0                     0   \n",
       "13                     0                     0                     0   \n",
       "14                     0                     0                     0   \n",
       "15                     0                     0                     0   \n",
       "16                     0                     0                     0   \n",
       "17                     0                     0                     0   \n",
       "18                     0                     0                     0   \n",
       "19                     0                     0                     0   \n",
       "20                     0                     0                     0   \n",
       "21                     1                     0                     0   \n",
       "22                     0                     0                     0   \n",
       "23                     0                     0                     0   \n",
       "24                     0                     0                     0   \n",
       "25                     0                     0                     0   \n",
       "26                     0                     0                     0   \n",
       "27                     0                     0                     0   \n",
       "28                     0                     0                     0   \n",
       "29                     0                     0                     0   \n",
       "..                   ...                   ...                   ...   \n",
       "388                    0                     0                     0   \n",
       "389                    0                     0                     0   \n",
       "390                    0                     0                     0   \n",
       "391                    0                     0                     0   \n",
       "392                    0                     0                     0   \n",
       "393                    0                     0                     0   \n",
       "394                    0                     0                     0   \n",
       "395                    0                     0                     0   \n",
       "396                    0                     0                     0   \n",
       "397                    0                     0                     0   \n",
       "398                    0                     0                     0   \n",
       "399                    0                     0                     0   \n",
       "400                    0                     0                     0   \n",
       "401                    0                     0                     0   \n",
       "402                    0                     0                     0   \n",
       "403                    0                     0                     0   \n",
       "404                    0                     0                     0   \n",
       "405                    0                     0                     0   \n",
       "406                    0                     0                     0   \n",
       "407                    1                     0                     0   \n",
       "408                    0                     0                     0   \n",
       "409                    0                     0                     0   \n",
       "410                    0                     0                     0   \n",
       "411                    1                     0                     0   \n",
       "412                    0                     0                     0   \n",
       "413                    0                     0                     0   \n",
       "414                    0                     1                     0   \n",
       "415                    0                     0                     0   \n",
       "416                    0                     0                     0   \n",
       "417                    0                     0                     0   \n",
       "\n",
       "     Cabin_number_200-250  Cabin_number_250-300  Cabin_number_300+  Pclass_1  \\\n",
       "0                       0                     0                  0         0   \n",
       "1                       0                     0                  0         1   \n",
       "2                       0                     0                  0         0   \n",
       "3                       0                     0                  0         1   \n",
       "4                       0                     0                  0         0   \n",
       "5                       0                     0                  0         0   \n",
       "6                       0                     0                  0         1   \n",
       "7                       0                     0                  0         0   \n",
       "8                       0                     0                  0         0   \n",
       "9                       0                     0                  0         0   \n",
       "10                      0                     0                  0         0   \n",
       "11                      0                     0                  0         1   \n",
       "12                      0                     0                  0         0   \n",
       "13                      0                     0                  0         0   \n",
       "14                      0                     0                  0         0   \n",
       "15                      0                     0                  0         0   \n",
       "16                      0                     0                  0         0   \n",
       "17                      0                     0                  0         0   \n",
       "18                      0                     0                  0         0   \n",
       "19                      0                     0                  0         0   \n",
       "20                      0                     0                  0         0   \n",
       "21                      0                     0                  0         0   \n",
       "22                      0                     0                  0         0   \n",
       "23                      0                     0                  0         1   \n",
       "24                      0                     0                  0         0   \n",
       "25                      0                     0                  0         0   \n",
       "26                      0                     0                  0         0   \n",
       "27                      0                     0                  0         1   \n",
       "28                      0                     0                  0         0   \n",
       "29                      0                     0                  0         0   \n",
       "..                    ...                   ...                ...       ...   \n",
       "388                     0                     0                  0         0   \n",
       "389                     0                     0                  0         0   \n",
       "390                     0                     0                  0         1   \n",
       "391                     0                     0                  0         1   \n",
       "392                     0                     0                  0         0   \n",
       "393                     0                     0                  0         0   \n",
       "394                     0                     0                  0         0   \n",
       "395                     0                     0                  0         1   \n",
       "396                     0                     0                  0         0   \n",
       "397                     0                     0                  0         1   \n",
       "398                     0                     0                  0         0   \n",
       "399                     0                     0                  0         0   \n",
       "400                     0                     0                  0         1   \n",
       "401                     0                     0                  0         0   \n",
       "402                     0                     0                  0         1   \n",
       "403                     0                     0                  0         1   \n",
       "404                     0                     0                  0         1   \n",
       "405                     0                     0                  0         0   \n",
       "406                     0                     0                  0         0   \n",
       "407                     0                     0                  0         1   \n",
       "408                     0                     0                  0         0   \n",
       "409                     0                     0                  0         0   \n",
       "410                     0                     0                  0         0   \n",
       "411                     0                     0                  0         1   \n",
       "412                     0                     0                  0         0   \n",
       "413                     0                     0                  0         0   \n",
       "414                     0                     0                  0         1   \n",
       "415                     0                     0                  0         0   \n",
       "416                     0                     0                  0         0   \n",
       "417                     0                     0                  0         0   \n",
       "\n",
       "     Pclass_2  Pclass_3  \n",
       "0           0         1  \n",
       "1           0         0  \n",
       "2           0         1  \n",
       "3           0         0  \n",
       "4           0         1  \n",
       "5           0         1  \n",
       "6           0         0  \n",
       "7           0         1  \n",
       "8           0         1  \n",
       "9           1         0  \n",
       "10          0         1  \n",
       "11          0         0  \n",
       "12          0         1  \n",
       "13          0         1  \n",
       "14          0         1  \n",
       "15          1         0  \n",
       "16          0         1  \n",
       "17          1         0  \n",
       "18          0         1  \n",
       "19          0         1  \n",
       "20          1         0  \n",
       "21          1         0  \n",
       "22          0         1  \n",
       "23          0         0  \n",
       "24          0         1  \n",
       "25          0         1  \n",
       "26          0         1  \n",
       "27          0         0  \n",
       "28          0         1  \n",
       "29          0         1  \n",
       "..        ...       ...  \n",
       "388         0         1  \n",
       "389         0         1  \n",
       "390         0         0  \n",
       "391         0         0  \n",
       "392         0         1  \n",
       "393         1         0  \n",
       "394         0         1  \n",
       "395         0         0  \n",
       "396         0         1  \n",
       "397         0         0  \n",
       "398         0         1  \n",
       "399         0         1  \n",
       "400         0         0  \n",
       "401         1         0  \n",
       "402         0         0  \n",
       "403         0         0  \n",
       "404         0         0  \n",
       "405         1         0  \n",
       "406         1         0  \n",
       "407         0         0  \n",
       "408         0         1  \n",
       "409         0         1  \n",
       "410         0         1  \n",
       "411         0         0  \n",
       "412         0         1  \n",
       "413         0         1  \n",
       "414         0         0  \n",
       "415         0         1  \n",
       "416         0         1  \n",
       "417         0         1  \n",
       "\n",
       "[1309 rows x 90 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(transformed_data.columns)\n",
    "transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all columns are numeric, if only index are displayed\n",
    "transformed_data.select_dtypes(['object', 'category']).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / hold out data\n",
    "train = transformed_data.iloc[:891]\n",
    "holdout = transformed_data.iloc[891:]\n",
    "\n",
    "# X, y split\n",
    "X = train\n",
    "y = survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Models and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "------------------\n",
      "Number of Features: 90\n",
      "\n",
      "Best Score: 0.813692480359147\n",
      "\n",
      "Best Parameters: {'solver': 'newton-cg'}\n",
      "\n",
      "KNeighborsClassifier\n",
      "--------------------\n",
      "Number of Features: 90\n",
      "\n",
      "Best Score: 0.5499438832772167\n",
      "\n",
      "Best Parameters: {'algorithm': 'ball_tree', 'n_neighbors': 1, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n",
      "Number of Features: 90\n",
      "\n",
      "Best Score: 0.8271604938271605\n",
      "\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def find_best_model(X, y, list_features='all'):\n",
    "    \n",
    "    all_X = X\n",
    "    all_y = y\n",
    "\n",
    "    # List of dictionaries, each containing a model name,\n",
    "    # it's estimator and a dict of hyperparameters\n",
    "    models = [\n",
    "        {\n",
    "            \"name\": \"LogisticRegression\",\n",
    "            \"estimator\": LogisticRegression(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"KNeighborsClassifier\",\n",
    "            \"estimator\": KNeighborsClassifier(n_neighbors=10),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"n_neighbors\": range(1,20,2),\n",
    "                    \"weights\": [\"distance\", \"uniform\"],\n",
    "                    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                    \"p\": [1, 2]\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RandomForestClassifier\",\n",
    "            \"estimator\": RandomForestClassifier(random_state=1, n_estimators=100),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"n_estimators\": [100, 200],\n",
    "                    \"criterion\": [\"entropy\", \"gini\"],\n",
    "                    \"max_depth\": [10, 20],\n",
    "                    \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                    \"min_samples_leaf\": [1, 2],\n",
    "                    \"min_samples_split\": [2]\n",
    "                }\n",
    "        }\n",
    "#         },\n",
    "#         {\n",
    "#             \"name\":\"SVC\",\n",
    "#             \"estimator\":SVC(),\n",
    "#             \"hyperparameters\":\n",
    "#                 {\n",
    "#                   \"kernel\": ['rbf', 'linear'],  \n",
    "#                   \"C\": [0.1, 1],\n",
    "#                   \"gamma\": [0.01, 0.1]\n",
    "#                 }\n",
    "#         },\n",
    "#         {\n",
    "#             \"name\": \"PassiveAgressiveC\",\n",
    "#             \"estimator\": PassiveAggressiveClassifier(random_state=1),\n",
    "#             \"hyperparameters\":\n",
    "#                 {\n",
    "#                     \"C\": [.5, 1, 1.5],\n",
    "#                     \"warm_start\": [True, False]\n",
    "#                 }\n",
    "#         },\n",
    "#         {\n",
    "#             \"name\": \"GaussianProcess\",\n",
    "#                 \"estimator\": GaussianProcessClassifier(),\n",
    "#                 \"hyperparameters\":\n",
    "#                 {\n",
    "#                     \"n_restarts_optimizer\": [0, 1, 2],\n",
    "#                     \"warm_start\": [True, False]\n",
    "#                 }\n",
    "#         }\n",
    "    ]\n",
    "    counter = 0\n",
    "    for model in models:\n",
    "        # Without feature selection\n",
    "        if list_features == 'all':\n",
    "            features = X.columns\n",
    "        else:\n",
    "            features = list_features[counter]\n",
    "            counter += 1\n",
    "        \n",
    "        # Train multiple versions of the models\n",
    "        grid = GridSearchCV(model[\"estimator\"],\n",
    "                            param_grid=model[\"hyperparameters\"],\n",
    "                            cv=3,\n",
    "                            n_jobs=-1)\n",
    "        grid.fit(all_X[features], all_y)\n",
    "        \n",
    "        # Saves the best results\n",
    "        model[\"best_features\"] = features\n",
    "        model[\"best_params\"] = grid.best_params_\n",
    "        model[\"best_score\"] = grid.best_score_\n",
    "        model[\"best_model\"] = grid.best_estimator_\n",
    "        \n",
    "        # Show best results\n",
    "        print(model['name'])\n",
    "        print('-'*len(model['name']))\n",
    "        print(\"Number of Features: {}\\n\".format(len(features)))\n",
    "        print(\"Best Score: {}\\n\".format(model[\"best_score\"]))\n",
    "        print(\"Best Parameters: {}\\n\".format(model[\"best_params\"]))\n",
    "\n",
    "    return models\n",
    "\n",
    "best_models = find_best_model(X, y, 'all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "------------------\n",
      "Number of Features: 90\n",
      "\n",
      "Best Score: 0.813692480359147\n",
      "\n",
      "Best Parameters: {'solver': 'newton-cg'}\n",
      "\n",
      "KNeighborsClassifier\n",
      "--------------------\n",
      "Number of Features: 90\n",
      "\n",
      "Best Score: 0.5499438832772167\n",
      "\n",
      "Best Parameters: {'algorithm': 'ball_tree', 'n_neighbors': 1, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n",
      "Number of Features: 32\n",
      "\n",
      "Best Score: 0.8428731762065096\n",
      "\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_best_features(X, y, models):\n",
    "    \"\"\"\n",
    "    Find the best features using REFCV for each model.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    for model in models:\n",
    "        # Find best features for each model's settings\n",
    "        try:\n",
    "            selector = RFECV(model[\"estimator\"], cv=3, n_jobs=-1)\n",
    "            selector.fit(X, y)\n",
    "            features = list(X.columns[selector.support_])\n",
    "        except RuntimeError:\n",
    "            features = X.columns\n",
    "        \n",
    "        # Saves results\n",
    "        model[\"best_features\"] = features\n",
    "        features_list.append(features)\n",
    "        \n",
    "    return models, features_list\n",
    "\n",
    "best_features, feat_list = find_best_features(X, y, best_models)\n",
    "\n",
    "best_models = find_best_model(X, y, feat_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "------------------\n",
      "Number of Features: 90\n",
      "\n",
      "Best Score: 0.819304152637486\n",
      "\n",
      "Best Parameters: {'C': 0.8497855787795136, 'class_weight': None, 'max_iter': 284, 'solver': 'lbfgs', 'warm_start': False}\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n",
      "Number of Features: 32\n",
      "\n",
      "Best Score: 0.8316498316498316\n",
      "\n",
      "Best Parameters: {'bootstrap': True, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 11, 'n_estimators': 160}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For the top 3 previous estimators RandomForest, LogisiticRegression and SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "def train_multiple_models_random(X, y, selected_features, n_iter):\n",
    "    \n",
    "    all_X = X\n",
    "    all_y = y\n",
    "\n",
    "    # List of dictionaries, each containing a model name,\n",
    "    # it's estimator and a dict of hyperparameters\n",
    "    new_models = [\n",
    "        {\n",
    "            \"name\": \"LogisticRegression\",\n",
    "            \"estimator\": LogisticRegression(n_jobs=-1),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                    \"class_weight\": ['balanced', None],\n",
    "                    \"C\": uniform(.1, 2),\n",
    "                    \"warm_start\":[True, False],\n",
    "                    \"max_iter\": randint(200, 10000),\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RandomForestClassifier\",\n",
    "            \"estimator\": RandomForestClassifier(random_state=1),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                  \"max_depth\": randint(5, 50),\n",
    "                  \"n_estimators\": randint(150, 500),\n",
    "                  \"min_samples_split\": randint(2, 50),\n",
    "                  \"min_samples_leaf\": randint(1, 50),\n",
    "                  \"bootstrap\": [True, False],\n",
    "                  \"max_features\": [\"log2\", \"sqrt\"]\n",
    "                }\n",
    "        }\n",
    "#        },\n",
    "#         {\n",
    "#             \"name\":\"SVC\",\n",
    "#             \"estimator\":SVC(),\n",
    "#             \"hyperparameters\":\n",
    "#                 {\n",
    "#                   \"kernel\": ['rbf', 'linear', 'poly', 'sigmoid'],  \n",
    "#                   \"degree\": randint(2, 5),\n",
    "#                   \"coef0\": uniform(-3., 3.),\n",
    "#                   \"C\": [0.001, 0.01, .1, 1],\n",
    "#                   \"gamma\": [0.001, 0.01, .1, 1]\n",
    "#                 }\n",
    "#         }\n",
    "    ]\n",
    "\n",
    "    for model in new_models:\n",
    "        # Get features from previous training\n",
    "        features = selected_features[model['name']]\n",
    "        \n",
    "        # Train multiple versions of the models\n",
    "        randsearch = RandomizedSearchCV(model[\"estimator\"],\n",
    "                                  param_distributions =model[\"hyperparameters\"],\n",
    "                                  n_iter=n_iter[model['name']],\n",
    "                                  cv=3,\n",
    "                                  n_jobs=-1,\n",
    "                                  scoring='accuracy'\n",
    "                                 )\n",
    "        randsearch.fit(all_X[features], all_y)\n",
    "        \n",
    "        # Saves the best results\n",
    "        model[\"best_features\"] = features\n",
    "        model[\"best_params\"] = randsearch.best_params_\n",
    "        model[\"best_score\"] = randsearch.best_score_\n",
    "        model[\"best_model\"] = randsearch.best_estimator_\n",
    "        \n",
    "        # Show best results\n",
    "        print(model['name'])\n",
    "        print('-'*len(model['name']))\n",
    "        print(\"Number of Features: {}\\n\".format(len(features)))\n",
    "        print(\"Best Score: {}\\n\".format(model[\"best_score\"]))\n",
    "        print(\"Best Parameters: {}\\n\".format(model[\"best_params\"]))\n",
    "\n",
    "    return new_models\n",
    "n_iter = {\"LogisticRegression\": 300,\n",
    "          \"SVC\": 20,\n",
    "          \"RandomForestClassifier\": 120}\n",
    "\n",
    "selected_features = {model[\"name\"]:model[\"best_features\"] for model in best_features}\n",
    "best_models_random = train_multiple_models_random(X, y, selected_features, n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_file(holdout, model, filename):\n",
    "    \"\"\"\n",
    "    Saves output for best models.\n",
    "    \"\"\"\n",
    "    # Predictions for given input\n",
    "    predictions = model[\"best_model\"].predict(holdout[model['best_features']])\n",
    "    \n",
    "    holdout_ids = holdout[\"PassengerId\"]\n",
    "    submission_df = {\"PassengerId\": holdout_ids,\n",
    "                     \"Survived\": predictions}\n",
    "    \n",
    "    submission = pd.DataFrame(submission_df)\n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "def get_best_model(list_models, top_k=1):\n",
    "    \"\"\"\n",
    "    Returns top_k best models from grid and random search.\n",
    "    \n",
    "    > list_models: The list of models\n",
    "    > top_k: the number of best models to be exported\n",
    "    \n",
    "    < list_estimator: List with the top_k estimators\n",
    "    \"\"\"\n",
    "    return sorted(list_models, key=lambda k: k['best_score'], reverse=True) \n",
    "    \n",
    "# Models\n",
    "model_grid = get_best_model(best_models)\n",
    "model_rand = get_best_model(best_models_random)\n",
    "\n",
    "save_submission_file(holdout, model_grid[0], \"submission_13.csv\")\n",
    "save_submission_file(holdout, model_rand[0], \"submission_14.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic: Machine Learning from Disaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 14.0kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit titanic -f submission_13.csv -m \"Random Forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic: Machine Learning from Disaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 14.1kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit titanic -f submission_14.csv -m \"Logistic Regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'LogisticRegression',\n",
       "  'estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  'hyperparameters': {'solver': ['newton-cg',\n",
       "    'lbfgs',\n",
       "    'liblinear',\n",
       "    'sag',\n",
       "    'saga'],\n",
       "   'class_weight': ['balanced', None],\n",
       "   'max_iter': <scipy.stats._distn_infrastructure.rv_frozen at 0x22a3defa128>},\n",
       "  'best_features': ['Family_size',\n",
       "   'Male',\n",
       "   'Age_Infant',\n",
       "   'Age_Adult',\n",
       "   'Age_Senior',\n",
       "   'Fare_50-100',\n",
       "   'Fare_100+',\n",
       "   'Ticket_cod_A4',\n",
       "   'Ticket_cod_A5',\n",
       "   'Ticket_cod_C',\n",
       "   'Ticket_cod_FC',\n",
       "   'Ticket_cod_PC',\n",
       "   'Ticket_cod_PP',\n",
       "   'Ticket_cod_SOC',\n",
       "   'Ticket_cod_SOPP',\n",
       "   'Ticket_cod_STONO',\n",
       "   'Ticket_cod_SWPP',\n",
       "   'Ticket_cod_WC',\n",
       "   'Ticket_number_Unknown',\n",
       "   'Ticket_number_3k-10k',\n",
       "   'Ticket_number_10k-20k',\n",
       "   'Ticket_number_300k+',\n",
       "   'Title_Master',\n",
       "   'Title_Miss',\n",
       "   'Title_Mr',\n",
       "   'Title_Mrs',\n",
       "   'Title_Officer',\n",
       "   'Cabin_type_B',\n",
       "   'Cabin_type_D',\n",
       "   'Cabin_type_E',\n",
       "   'Cabin_type_G',\n",
       "   'Cabin_number_0-33',\n",
       "   'Cabin_number_100-133',\n",
       "   'Cabin_number_133+',\n",
       "   'Pclass_1',\n",
       "   'Pclass_2'],\n",
       "  'best_params': {'class_weight': None, 'max_iter': 932, 'solver': 'saga'},\n",
       "  'best_score': 0.8383838383838383,\n",
       "  'best_model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=932, multi_class='ovr', n_jobs=-1,\n",
       "            penalty='l2', random_state=None, solver='saga', tol=0.0001,\n",
       "            verbose=0, warm_start=False)},\n",
       " {'name': 'RandomForestClassifier',\n",
       "  'estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "  'hyperparameters': {'max_depth': [3, None],\n",
       "   'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen at 0x22a3defa4a8>,\n",
       "   'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen at 0x22a3defa4e0>,\n",
       "   'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen at 0x22a3defa6d8>,\n",
       "   'bootstrap': [True, False],\n",
       "   'max_features': ['log2', 'sqrt']},\n",
       "  'best_features': ['PassengerId',\n",
       "   'SibSp',\n",
       "   'Parch',\n",
       "   'Family_size',\n",
       "   'Alone',\n",
       "   'Male',\n",
       "   'Age_Missing',\n",
       "   'Age_Infant',\n",
       "   'Age_Child',\n",
       "   'Age_Teenager',\n",
       "   'Age_Young Adult',\n",
       "   'Age_Adult',\n",
       "   'Age_Senior',\n",
       "   'Fare_0-12',\n",
       "   'Fare_12-50',\n",
       "   'Fare_50-100',\n",
       "   'Fare_100+',\n",
       "   'Embarked_C',\n",
       "   'Embarked_Q',\n",
       "   'Embarked_S',\n",
       "   'Ticket_cod_A4',\n",
       "   'Ticket_cod_A5',\n",
       "   'Ticket_cod_AS',\n",
       "   'Ticket_cod_C',\n",
       "   'Ticket_cod_CA',\n",
       "   'Ticket_cod_FC',\n",
       "   'Ticket_cod_FCC',\n",
       "   'Ticket_cod_LINE',\n",
       "   'Ticket_cod_PC',\n",
       "   'Ticket_cod_PP',\n",
       "   'Ticket_cod_SCAH',\n",
       "   'Ticket_cod_SCPARIS',\n",
       "   'Ticket_cod_SCParis',\n",
       "   'Ticket_cod_SOC',\n",
       "   'Ticket_cod_SOP',\n",
       "   'Ticket_cod_SOPP',\n",
       "   'Ticket_cod_SOTONOQ',\n",
       "   'Ticket_cod_STONO',\n",
       "   'Ticket_cod_STONO2',\n",
       "   'Ticket_cod_SWPP',\n",
       "   'Ticket_cod_WC',\n",
       "   'Ticket_cod_WEP',\n",
       "   'Ticket_cod_X',\n",
       "   'Ticket_number_Unknown',\n",
       "   'Ticket_number_0-3k',\n",
       "   'Ticket_number_3k-10k',\n",
       "   'Ticket_number_10k-20k',\n",
       "   'Ticket_number_20k-50k',\n",
       "   'Ticket_number_50k-100k',\n",
       "   'Ticket_number_100k-300k',\n",
       "   'Ticket_number_300k+',\n",
       "   'Title_Master',\n",
       "   'Title_Miss',\n",
       "   'Title_Mr',\n",
       "   'Title_Mrs',\n",
       "   'Title_Officer',\n",
       "   'Title_Royalty',\n",
       "   'Cabin_type_A',\n",
       "   'Cabin_type_B',\n",
       "   'Cabin_type_C',\n",
       "   'Cabin_type_D',\n",
       "   'Cabin_type_E',\n",
       "   'Cabin_type_F',\n",
       "   'Cabin_type_G',\n",
       "   'Cabin_type_T',\n",
       "   'Cabin_type_Unknown',\n",
       "   'Cabin_number_Unknown',\n",
       "   'Cabin_number_0-33',\n",
       "   'Cabin_number_33-67',\n",
       "   'Cabin_number_67-100',\n",
       "   'Cabin_number_100-133',\n",
       "   'Cabin_number_133+',\n",
       "   'Pclass_1',\n",
       "   'Pclass_2',\n",
       "   'Pclass_3'],\n",
       "  'best_params': {'bootstrap': False,\n",
       "   'max_depth': None,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_leaf': 7,\n",
       "   'min_samples_split': 31,\n",
       "   'n_estimators': 224},\n",
       "  'best_score': 0.8361391694725028,\n",
       "  'best_model': RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=7, min_samples_split=31,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=224, n_jobs=1,\n",
       "              oob_score=False, random_state=1, verbose=0, warm_start=False)}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VddvfkrFbL4u"
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_ticket(df):\n",
    "    # see https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "    ticket = []\n",
    "    ticket_number = []\n",
    "    for i in list(df.Ticket):\n",
    "        if not i.isdigit():\n",
    "            # Take prefix\n",
    "            split = i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')\n",
    "            ticket.append(split[0])\n",
    "            # Take ticket number\n",
    "            ticket_number.append(split[1])\n",
    "        else:\n",
    "            ticket.append(\"X\")\n",
    "            ticket.append(np.nan)\n",
    "    df[\"Ticket\"] = Ticket\n",
    "    df[\"Ticket_Number\"] = Ticket\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_missing(df):\n",
    "    \"\"\"Handle various missing values from the data set\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    holdout = process_missing(holdout)\n",
    "    \"\"\"\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].mean())\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    return df\n",
    "\n",
    "def process_age(df):\n",
    "    \"\"\"Process the Age column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_age(train)\n",
    "    \"\"\"\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    cut_points = [-1,0,5,12,18,35,60,100]\n",
    "    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    \n",
    "    #df = df.drop(\"Age\",axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_fare(df):\n",
    "    \"\"\"Process the Fare column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_fare(train)\n",
    "    \"\"\"\n",
    "    cut_points = [-1,12,50,100,1000]\n",
    "    label_names = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n",
    "    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],cut_points,labels=label_names)\n",
    "    \n",
    "    df = df.drop(\"Fare\",axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_cabin(df):\n",
    "    \"\"\"Process the Cabin column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train process_cabin(train)\n",
    "    \"\"\"\n",
    "    df[\"Cabin_type\"] = df[\"Cabin\"].str[0]\n",
    "    df[\"Cabin_type\"] = df[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "    df = df.drop('Cabin',axis=1)\n",
    "    return df\n",
    "\n",
    "def process_titles(df):\n",
    "    \"\"\"Extract and categorize the title from the name column \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_titles(train)\n",
    "    \"\"\"\n",
    "    titles = {\n",
    "        \"Mr\" :         \"Mr\",\n",
    "        \"Mme\":         \"Mrs\",\n",
    "        \"Ms\":          \"Mrs\",\n",
    "        \"Mrs\" :        \"Mrs\",\n",
    "        \"Master\" :     \"Master\",\n",
    "        \"Mlle\":        \"Miss\",\n",
    "        \"Miss\" :       \"Miss\",\n",
    "        \"Capt\":        \"Officer\",\n",
    "        \"Col\":         \"Officer\",\n",
    "        \"Major\":       \"Officer\",\n",
    "        \"Dr\":          \"Officer\",\n",
    "        \"Rev\":         \"Officer\",\n",
    "        \"Jonkheer\":    \"Royalty\",\n",
    "        \"Don\":         \"Royalty\",\n",
    "        \"Sir\" :        \"Royalty\",\n",
    "        \"Countess\":    \"Royalty\",\n",
    "        \"Dona\":        \"Royalty\",\n",
    "        \"Lady\" :       \"Royalty\"\n",
    "    }\n",
    "    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "    df[\"Title\"] = extracted_titles.map(titles)\n",
    "    return df\n",
    "\n",
    "def create_dummies(df,column_name):\n",
    "    \"\"\"Create Dummy Columns (One Hot Encoding) from a single Column\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = create_dummies(train,\"Age\")\n",
    "    \"\"\"\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9jIVSrSbL4w"
   },
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    df = process_ticket(df)\n",
    "    df = process_missing(df)\n",
    "    df = process_age(df)\n",
    "    df = process_fare(df)\n",
    "    df = process_titles(df)\n",
    "    df = process_cabin(df)\n",
    "\n",
    "    for col in [\"Age_categories\",\"Fare_categories\",\n",
    "                \"Title\",\"Cabin_type\",\"Sex\",\"Ticket\",\"Pclass\"]:\n",
    "        df = create_dummies(df,col)\n",
    "    \n",
    "    #df = df.drop([\"Age_categories\",\"Fare_categories\",\n",
    "                #\"Title\",\"Cabin_type\",\"Sex\",\"Ticket\"],axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "all_data = pre_process(all_data)\n",
    "\n",
    "train = all_data.iloc[:891]\n",
    "train = pd.concat([train,survived],axis=1)\n",
    "holdout = all_data.iloc[891:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvTOyioebL4z"
   },
   "source": [
    "# 4 - Exploring Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlNqa8AmbL4z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 3 columns):\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Survived    891 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 27.8 KB\n"
     ]
    }
   ],
   "source": [
    "explore_cols = [\"SibSp\",\"Parch\",\"Survived\"]\n",
    "explore = train[explore_cols].copy()\n",
    "explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kekhl5qbL44"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "explore.drop(\"Survived\",axis=1).plot.hist(alpha=0.5,bins=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "75z57Jx_bL47"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore[\"familysize\"] = explore[[\"SibSp\",\"Parch\"]].sum(axis=1)\n",
    "explore.drop(\"Survived\",axis=1).plot.hist(alpha=0.5,bins=10)\n",
    "plt.xticks(range(11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrMEhJ2GbL5A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "plt.clf()\n",
    "for col in explore.columns.drop(\"Survived\"):\n",
    "    pivot = explore.pivot_table(index=col,values=\"Survived\")\n",
    "    pivot.plot.bar(ylim=(0,1),yticks=np.arange(0,1,.1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HdONhP9bL5E"
   },
   "source": [
    "The SibSp column shows the number of siblings and/or spouses each passenger had on board, while the Parch columns shows the number of parents or children each passenger had onboard. Neither column has any missing values.\n",
    "\n",
    "The distribution of values in both columns is skewed right, with the majority of values being zero.\n",
    "\n",
    "You can sum these two columns to explore the total number of family members each passenger had onboard. The shape of the distribution of values in this case is similar, however there are less values at zero, and the quantity tapers off less rapidly as the values increase.\n",
    "\n",
    "Looking at the survival rates of the the combined family members, you can see that few of the over 500 passengers with no family members survived, while greater numbers of passengers with family members survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAn_tn1bbL5G"
   },
   "source": [
    "# 5 - Engineering New Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9R33kK4bL5H",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\program files\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "def process_isalone(df):\n",
    "    df[\"familysize\"] = df[[\"SibSp\",\"Parch\"]].sum(axis=1)\n",
    "    df[\"isalone\"] = 0\n",
    "    df.loc[(df[\"familysize\"] == 0),\"isalone\"] = 1\n",
    "    #df = df.drop(\"familysize\",axis=1)\n",
    "    return df\n",
    "\n",
    "train = process_isalone(train)\n",
    "holdout = process_isalone(holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2OtjzNRbbL5K"
   },
   "source": [
    "# 6 - Selecting the Best-Performing Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-2kSrkUbL5L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Columns \n",
      "------------\n",
      "['Pclass', 'Age', 'SibSp', 'Parch', 'Age_categories_Missing', 'Age_categories_Infant', 'Age_categories_Child', 'Age_categories_Teenager', 'Age_categories_Young Adult', 'Age_categories_Adult', 'Age_categories_Senior', 'Fare_categories_0-12', 'Fare_categories_12-50', 'Fare_categories_50-100', 'Fare_categories_100+', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Title_Royalty', 'Cabin_type_A', 'Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D', 'Cabin_type_E', 'Cabin_type_F', 'Cabin_type_G', 'Cabin_type_T', 'Cabin_type_Unknown', 'Sex_female', 'Sex_male', 'Ticket_A4', 'Ticket_A5', 'Ticket_AS', 'Ticket_C', 'Ticket_CA', 'Ticket_CASOTON', 'Ticket_FC', 'Ticket_FCC', 'Ticket_LINE', 'Ticket_PC', 'Ticket_PP', 'Ticket_PPP', 'Ticket_SC', 'Ticket_SCAH', 'Ticket_SCOW', 'Ticket_SCPARIS', 'Ticket_SCParis', 'Ticket_SOC', 'Ticket_SOP', 'Ticket_SOPP', 'Ticket_SOTONO2', 'Ticket_SOTONOQ', 'Ticket_SP', 'Ticket_STONO', 'Ticket_STONO2', 'Ticket_SWPP', 'Ticket_WC', 'Ticket_WEP', 'Ticket_X', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'familysize', 'isalone']\n",
      "\n",
      "Best Columns \n",
      "------------\n",
      "['Age_categories_Infant', 'Age_categories_Adult', 'Age_categories_Senior', 'Fare_categories_50-100', 'Fare_categories_100+', 'Title_Master', 'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Cabin_type_D', 'Cabin_type_E', 'Cabin_type_G', 'Cabin_type_Unknown', 'Sex_female', 'Sex_male', 'Ticket_C', 'Ticket_FC', 'Ticket_FCC', 'Ticket_LINE', 'Ticket_PP', 'Ticket_SOC', 'Ticket_SOPP', 'Ticket_STONO', 'Ticket_SWPP', 'Ticket_WC', 'Ticket_WEP', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'familysize']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def select_features(df,index):\n",
    "    \n",
    "    # index\n",
    "    # 0 - random forest\n",
    "    # 1 - logistic regression\n",
    "    \n",
    "    # Remove non-numeric columns, columns that have null values\n",
    "    df = df.select_dtypes([np.number]).dropna(axis=1)\n",
    "    all_X = df.drop([\"Survived\",\"PassengerId\"],axis=1)\n",
    "    all_y = df[\"Survived\"]\n",
    "    \n",
    "    clf_rf = RandomForestClassifier(random_state=1, n_estimators=100)\n",
    "    clf_lr = LogisticRegression()\n",
    "    clfs = [clf_rf,clf_lr]\n",
    "    \n",
    "    selector = RFECV(clfs[index],cv=10,n_jobs=-1)\n",
    "    selector.fit(all_X,all_y)\n",
    "    \n",
    "    best_columns = list(all_X.columns[selector.support_])\n",
    "    print(\"Best Columns \\n\"+\"-\"*12+\"\\n{}\\n\".format(best_columns))\n",
    "    \n",
    "    return best_columns\n",
    "\n",
    "cols_rf = select_features(train,0)\n",
    "cols_lr = select_features(train,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Dimensionality with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_categories_Missing</th>\n",
       "      <th>Age_categories_Infant</th>\n",
       "      <th>Age_categories_Child</th>\n",
       "      <th>Age_categories_Teenager</th>\n",
       "      <th>Age_categories_Young Adult</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_STONOQ</th>\n",
       "      <th>Ticket_SWPP</th>\n",
       "      <th>Ticket_WC</th>\n",
       "      <th>Ticket_WEP</th>\n",
       "      <th>Ticket_X</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>familysize</th>\n",
       "      <th>isalone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch  Age_categories_Missing  \\\n",
       "0            1       3  22.0      1      0                       0   \n",
       "1            2       1  38.0      1      0                       0   \n",
       "2            3       3  26.0      0      0                       0   \n",
       "3            4       1  35.0      1      0                       0   \n",
       "4            5       3  35.0      0      0                       0   \n",
       "\n",
       "   Age_categories_Infant  Age_categories_Child  Age_categories_Teenager  \\\n",
       "0                      0                     0                        0   \n",
       "1                      0                     0                        0   \n",
       "2                      0                     0                        0   \n",
       "3                      0                     0                        0   \n",
       "4                      0                     0                        0   \n",
       "\n",
       "   Age_categories_Young Adult   ...     Ticket_STONOQ  Ticket_SWPP  Ticket_WC  \\\n",
       "0                           1   ...                 0            0          0   \n",
       "1                           0   ...                 0            0          0   \n",
       "2                           1   ...                 0            0          0   \n",
       "3                           1   ...                 0            0          0   \n",
       "4                           1   ...                 0            0          0   \n",
       "\n",
       "   Ticket_WEP  Ticket_X  Pclass_1  Pclass_2  Pclass_3  familysize  isalone  \n",
       "0           0         0         0         0         1           1        0  \n",
       "1           0         0         1         0         0           1        0  \n",
       "2           0         0         0         0         1           0        1  \n",
       "3           0         1         1         0         0           1        0  \n",
       "4           0         1         0         0         1           0        1  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove string objects\n",
    "numeric_train = train.drop(train.select_dtypes(['object', 'category']), axis=1)\n",
    "numeric_train = numeric_train.drop('Survived', axis=1)\n",
    "\n",
    "numeric_holdout = holdout.drop(holdout.select_dtypes(['object', 'category']), axis=1)\n",
    "numeric_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.95143738e-01 4.72348596e-03 6.25217599e-05 1.84661108e-05\n",
      " 1.06211982e-05 7.19673291e-06 6.01403337e-06 4.60737333e-06\n",
      " 3.34539033e-06 2.68108665e-06 2.45778639e-06 1.74097749e-06\n",
      " 1.41485819e-06 1.33777509e-06 1.17503752e-06 9.98313660e-07\n",
      " 8.98239117e-07 8.07567301e-07 6.59890865e-07 5.85986717e-07\n",
      " 5.55264364e-07 5.38385035e-07 4.61272796e-07 4.17366845e-07\n",
      " 4.09133192e-07 3.05001006e-07 2.72388815e-07 2.32149771e-07\n",
      " 2.26596042e-07 1.82308036e-07 1.73905274e-07 1.43453778e-07\n",
      " 1.13114314e-07 1.06381695e-07 9.53305011e-08 8.92336344e-08\n",
      " 8.89575663e-08 8.61828768e-08 8.00831484e-08 7.33942208e-08\n",
      " 6.62808752e-08 6.39035013e-08 5.32296563e-08 4.77213136e-08\n",
      " 4.53756761e-08 3.68750488e-08 3.28880194e-08 3.24437276e-08\n",
      " 2.59239619e-08 2.08204398e-08 2.04757630e-08 1.82158070e-08\n",
      " 1.68822917e-08 1.68692695e-08 1.67158275e-08 1.66907293e-08\n",
      " 1.66280636e-08 1.62983783e-08 1.61782495e-08 1.57301677e-08]\n",
      "total components 75\n",
      "Relevant components 60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=60)\n",
    "\n",
    "train_modified = pca.fit_transform(numeric_train)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"total components\", numeric_train.shape[1])\n",
    "print(\"Relevant components\", train_modified.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AqooMKXdbL5N"
   },
   "source": [
    "# 7 - Selecting and Tuning Different Algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8uxMv_UxbL5O"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAgressiveClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "def select_model(df,features):\n",
    "    \n",
    "    all_X = df[features]\n",
    "    all_y = df[\"Survived\"]\n",
    "\n",
    "    # List of dictionaries, each containing a model name,\n",
    "    # it's estimator and a dict of hyperparameters\n",
    "    models = [\n",
    "        {\n",
    "            \"name\": \"LogisticRegression\",\n",
    "            \"estimator\": LogisticRegression(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"KNeighborsClassifier\",\n",
    "            \"estimator\": KNeighborsClassifier(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"n_neighbors\": range(1,20,2),\n",
    "                    \"weights\": [\"distance\", \"uniform\"],\n",
    "                    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                    \"p\": [1, 2]\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RandomForestClassifier\",\n",
    "            \"estimator\": RandomForestClassifier(random_state=1),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"n_estimators\": [100, 200],\n",
    "                    \"criterion\": [\"entropy\", \"gini\"],\n",
    "                    \"max_depth\": [10, 20],\n",
    "                    \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                    \"min_samples_leaf\": [1, 2],\n",
    "                    \"min_samples_split\": [2]\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"SVC\",\n",
    "            \"estimator\":SVC(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                  \"kernel\": ['rbf', 'linear'],  \n",
    "                  \"C\": [0.01, 0.1, 1],\n",
    "                  \"gamma\": [0.01, 0.1, 1]\n",
    "                }\n",
    "        },\n",
    "        \"name\": \"PassiveAgressiveC\",\n",
    "            \"estimator\": LogisticRegression(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "                }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for model in models:\n",
    "        print(model['name'])\n",
    "        print('-'*len(model['name']))\n",
    "\n",
    "        grid = GridSearchCV(model[\"estimator\"],\n",
    "                            param_grid=model[\"hyperparameters\"],\n",
    "                            cv=10)\n",
    "        grid.fit(all_X,all_y)\n",
    "        model[\"best_params\"] = grid.best_params_\n",
    "        model[\"best_score\"] = grid.best_score_\n",
    "        model[\"best_model\"] = grid.best_estimator_\n",
    "\n",
    "        print(\"Best Score: {}\".format(model[\"best_score\"]))\n",
    "        print(\"Best Parameters: {}\\n\".format(model[\"best_params\"]))\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeDDIj4TbL5Q",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "------------------\n",
      "Best Score: 0.8181818181818182\n",
      "Best Parameters: {'solver': 'newton-cg'}\n",
      "\n",
      "KNeighborsClassifier\n",
      "--------------------\n",
      "Best Score: 0.5353535353535354\n",
      "Best Parameters: {'algorithm': 'ball_tree', 'n_neighbors': 19, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-906b33a963b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_modified\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-122-7feda5338807>\u001b[0m in \u001b[0;36mselect_model\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m                             \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hyperparameters\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                             cv=10)\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_params\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_score\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_a = select_model(train_modified, train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-m8KwVTWbL5T"
   },
   "outputs": [],
   "source": [
    "result_b = select_model(train,cols_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0L9BQt8zbL5W"
   },
   "source": [
    "# 8 - Making a Submission to Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgvGjgR1bL5X"
   },
   "outputs": [],
   "source": [
    "def save_submission_file(model, pca_class, filename):\n",
    "    holdout_data = pca_class.transform(numeric_holdout)\n",
    "    predictions = model.predict(holdout_data)\n",
    "    \n",
    "    holdout_ids = holdout[\"PassengerId\"]\n",
    "    submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": predictions}\n",
    "    submission = pd.DataFrame(submission_df)\n",
    "\n",
    "    submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xbc3u4DlbL5Z"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 30 and input n_features is 60 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-71bfd3c21691>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_rf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msave_submission_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_rf_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"submission_23.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-104-cd13fd1338ad>\u001b[0m in \u001b[0;36msave_submission_file\u001b[1;34m(model, pca_class, filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msave_submission_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mholdout_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumeric_holdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdout_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mholdout_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mholdout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"PassengerId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    355\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    382\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 30 and input n_features is 60 "
     ]
    }
   ],
   "source": [
    "best_rf_model = result_b[2][\"best_model\"]\n",
    "save_submission_file(best_rf_model, pca,\"submission_23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yum7k-wwbL5b"
   },
   "source": [
    "#9 - Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0pNKdURxyJpK"
   },
   "source": [
    "\n",
    "\n",
    "We encourage you to continue working on this Kaggle competition. Here are some suggestions of next steps:\n",
    "\n",
    "- Continue to explore the data and create new features, following the workflow and using the functions we created.\n",
    "- Read more about the titanic and this Kaggle competition to get ideas for new features.\n",
    "- Use some different algorithms in the select_model() function, like [stochastic gradient descent](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) or [perceptron linear models](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html).\n",
    "- Experiment with [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) instead of **GridSearchCV** to speed up your **select_features()** function.\n",
    "\n",
    "Lastly, while the Titanic competition is great for learning about how to approach your first Kaggle competition, we recommend against spending many hours focused on trying to get to the top of the leaderboard. With such a small data set, there is a limit to how good your predictions can be, and your time would be better spent moving onto more complex competitions.\n",
    "\n",
    "Once you feel like you have a good understanding of the Kaggle workflow, you should look at some other competitions - a great next competition is the [House Prices Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). A start point you can find [here](https://www.dataquest.io/blog/kaggle-getting-started/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "4. Guided Project - Creating a Kaggle Workflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
